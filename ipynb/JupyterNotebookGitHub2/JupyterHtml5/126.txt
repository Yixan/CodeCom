
In [1]:

    
# These are all the modules we'll be using later. Make sure you can import them
# before proceeding further.
from __future__ import print_function
import numpy as np
import tensorflow as tf
from six.moves import cPickle as pickle


    



In [2]:

    
pickle_file = 'notMNIST.pickle'

with open(pickle_file, 'rb') as f:
  save = pickle.load(f)
  train_dataset = save['train_dataset']
  train_labels = save['train_labels']
  valid_dataset = save['valid_dataset']
  valid_labels = save['valid_labels']
  test_dataset = save['test_dataset']
  test_labels = save['test_labels']
  del save  # hint to help gc free up memory
  print('Training set', train_dataset.shape, train_labels.shape)
  print('Validation set', valid_dataset.shape, valid_labels.shape)
  print('Test set', test_dataset.shape, test_labels.shape)


    



In [3]:

    
image_size = 28
num_labels = 10

def reformat(dataset, labels):
  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)
  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]
  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)
  return dataset, labels
train_dataset, train_labels = reformat(train_dataset, train_labels)
valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)
test_dataset, test_labels = reformat(test_dataset, test_labels)
print('Training set', train_dataset.shape, train_labels.shape)
print('Validation set', valid_dataset.shape, valid_labels.shape)
print('Test set', test_dataset.shape, test_labels.shape)


    



In [4]:

    
def accuracy(predictions, labels):
  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))
          / predictions.shape[0])


    



In [9]:

    
batch_size = 128
beta=0.01
graph = tf.Graph()
with graph.as_default():

  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size))
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
  tf_valid_dataset = tf.constant(valid_dataset)
  tf_test_dataset = tf.constant(test_dataset)
  # Variables.
  weights = tf.Variable(
    tf.truncated_normal([image_size * image_size, num_labels]))
  biases = tf.Variable(tf.zeros([num_labels]))
  # Training computation.
  logits = tf.matmul(tf_train_dataset, weights) + biases
  loss = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))+ beta * tf.nn.l2_loss(weights)
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(logits)
  valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)
  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)


    



In [10]:

    
num_steps = 3001

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(
        valid_prediction.eval(), valid_labels))
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [17]:

    
batch_size = 128
n_nodes_hl1=1024
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  hidden_1_layer={'weights':tf.Variable(
  tf.truncated_normal([image_size * image_size, n_nodes_hl1]),name='hidden_weights'),'bias':tf.Variable(tf.zeros([n_nodes_hl1]),name='hidden_bias')}                                                                                                             
  output_layer={'weights':tf.Variable(tf.truncated_normal([n_nodes_hl1,num_labels]),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  output=tf.add(tf.matmul(l1,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"]))
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  


    



In [18]:

    
num_steps = 10000

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [21]:

    
batch_size = 10
n_nodes_hl1=1024
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  hidden_1_layer={'weights':tf.Variable(
  tf.truncated_normal([image_size * image_size, n_nodes_hl1]),name='hidden_weights'),'bias':tf.Variable(tf.zeros([n_nodes_hl1]),name='hidden_bias')}                                                                                                             
  output_layer={'weights':tf.Variable(tf.truncated_normal([n_nodes_hl1,num_labels]),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  output=tf.add(tf.matmul(l1,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"]))
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  


    



In [22]:

    
num_steps = 3001

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [31]:

    
batch_size = 20
n_nodes_hl1=2048
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  hidden_1_layer={'weights':tf.Variable(
  tf.truncated_normal([image_size * image_size, n_nodes_hl1]),name='hidden_weights'),'bias':tf.Variable(tf.zeros([n_nodes_hl1]),name='hidden_bias')}                                                                                                             
  output_layer={'weights':tf.Variable(tf.truncated_normal([n_nodes_hl1,num_labels]),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  output=tf.add(tf.matmul(l1,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"]))
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  


    



In [32]:

    
num_steps = 3001

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [25]:

    
batch_size = 1000
n_nodes_hl1=1024
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  hidden_1_layer={'weights':tf.Variable(
  tf.truncated_normal([image_size * image_size, n_nodes_hl1]),name='hidden_weights'),'bias':tf.Variable(tf.zeros([n_nodes_hl1]),name='hidden_bias')}                                                                                                             
  output_layer={'weights':tf.Variable(tf.truncated_normal([n_nodes_hl1,num_labels]),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  output=tf.add(tf.matmul(l1,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"]))
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  


    



In [37]:

    
batch_size = 128
n_nodes_hl1=2048
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  hidden_1_layer={'weights':tf.Variable(
  tf.truncated_normal([image_size * image_size, n_nodes_hl1]),name='hidden_weights'),'bias':tf.Variable(tf.zeros([n_nodes_hl1]),name='hidden_bias')}                                                                                                             
  output_layer={'weights':tf.Variable(tf.truncated_normal([n_nodes_hl1,num_labels]),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  hidden_1_layer["weights"]=tf.nn.dropout(hidden_1_layer["weights"],keep_prob=0.4) 
  output=tf.add(tf.matmul(l1,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"]))
  # Optimizer.
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  


    



In [38]:

    
num_steps = 3001

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [ ]:

    
 


    



In [ ]:

    
 


    



In [ ]:

    
 


    



In [ ]:

    
 


    



In [82]:

    
del output_layer


    



In [92]:

    
batch_size = 128 # 128
n_nodes_hl1=2024
n_nodes_hl2=1024
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  #tf.get_variable("W", shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer())
           
  hidden_1_layer={'weights':tf.get_variable(shape=[image_size * image_size, n_nodes_hl1],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl1]),name='hidden_bias')}
  hidden_2_layer={'weights':tf.get_variable( shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights_2'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl2]),name='hidden_bias_2')}
  output_layer={'weights':tf.get_variable( shape=[n_nodes_hl2,num_labels],initializer=tf.contrib.layers.xavier_initializer(),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  hidden_1_layer["weights"]=tf.nn.dropout(hidden_1_layer["weights"],keep_prob=0.5) 
  l2=tf.add(tf.matmul(l1,hidden_2_layer["weights"]),hidden_2_layer["bias"])
  l2=tf.nn.relu(l2)
  hidden_2_layer["weights"]=tf.nn.dropout(hidden_2_layer["weights"],keep_prob=0.5)   
  output=tf.add(tf.matmul(l2,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"])+tf.nn.l2_loss(hidden_2_layer["weights"]))
  # Optimizer.
  global_step = tf.Variable(0)  # count the number of steps taken.
  learning_rate = tf.train.exponential_decay(0.4, global_step,decay_steps=100,decay_rate=.96, staircase= False)
  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
  #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  # output=tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"])    
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))


    



In [93]:

    
num_steps = 10000

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [120]:

    
batch_size = 128 # 128
n_nodes_hl1=2048
n_nodes_hl2=2048
beta=0.0005
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  #tf.get_variable("W", shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer())
           
  hidden_1_layer={'weights':tf.get_variable(shape=[image_size * image_size, n_nodes_hl1],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl1]),name='hidden_bias')}
  hidden_2_layer={'weights':tf.get_variable( shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights_2'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl2]),name='hidden_bias_2')}
  output_layer={'weights':tf.get_variable( shape=[n_nodes_hl2,num_labels],initializer=tf.contrib.layers.xavier_initializer(),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.relu(l1)
  hidden_1_layer["weights"]=tf.nn.dropout(hidden_1_layer["weights"],keep_prob=0.7) 
  l2=tf.add(tf.matmul(l1,hidden_2_layer["weights"]),hidden_2_layer["bias"])
  l2=tf.nn.relu(l2)
  hidden_2_layer["weights"]=tf.nn.dropout(hidden_2_layer["weights"],keep_prob=0.3)   
  output=tf.add(tf.matmul(l2,output_layer["weights"]),output_layer["bias"])  
  #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"])+tf.nn.l2_loss(hidden_2_layer["weights"]))
  # Optimizer.
  global_step = tf.Variable(0)  # count the number of steps taken.
  learning_rate = tf.train.exponential_decay(0.4, global_step,decay_steps=100,decay_rate=.96, staircase= False)
  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
  #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  # output=tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"])    
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))


    



In [121]:

    
num_steps = 10000

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
 


    



In [104]:

    
batch_size = 128 # 128
n_nodes_hl1=2024
n_nodes_hl2=1024
beta=0.0008
graph = tf.Graph()
with graph.as_default():
  # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size),name='train')
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name='train_label')
  tf_valid_dataset = tf.constant(valid_dataset,name='valid')
  tf_test_dataset = tf.constant(test_dataset,name='test')
  #tf.get_variable("W", shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer())
           
  hidden_1_layer={'weights':tf.get_variable(shape=[image_size * image_size, n_nodes_hl1],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl1]),name='hidden_bias')}
  hidden_2_layer={'weights':tf.get_variable( shape=[n_nodes_hl1, n_nodes_hl2],initializer=tf.contrib.layers.xavier_initializer(),name='hidden_weights_2'),'bias':tf.Variable(tf.truncated_normal([n_nodes_hl2]),name='hidden_bias_2')}
  output_layer={'weights':tf.get_variable( shape=[n_nodes_hl2,num_labels],initializer=tf.contrib.layers.xavier_initializer(),name='output_weights'),'bias':tf.Variable(tf.truncated_normal([num_labels]),name='output_bias')}                                                                                                           
  l1=tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])
  l1=tf.nn.tanh(l1)
  hidden_1_layer["weights"]=tf.nn.dropout(hidden_1_layer["weights"],keep_prob=0.6) 
  l2=tf.add(tf.matmul(l1,hidden_2_layer["weights"]),hidden_2_layer["bias"])
  l2=tf.nn.relu(l2)
  hidden_2_layer["weights"]=tf.nn.dropout(hidden_2_layer["weights"],keep_prob=0.3)   
  output=tf.add(tf.matmul(l2,output_layer["weights"]),output_layer["bias"])  
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, tf_train_labels))+beta * (tf.nn.l2_loss(hidden_1_layer["weights"])+tf.nn.l2_loss(output_layer["weights"])+tf.nn.l2_loss(hidden_2_layer["weights"]))
  # Optimizer.
  global_step = tf.Variable(0)  # count the number of steps taken.
  learning_rate = tf.train.exponential_decay(0.4, global_step,decay_steps=100,decay_rate=.96, staircase= False)
  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
  #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(output)
  # output=tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_train_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"])    
  valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))
  test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset,hidden_1_layer["weights"]),hidden_1_layer["bias"])),hidden_2_layer["weights"]),hidden_2_layer["bias"])),output_layer["weights"]),output_layer["bias"]))


    



In [105]:

    
num_steps = 3001

with tf.Session(graph=graph) as session:
  tf.global_variables_initializer().run()
  print("Initialized")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print("Minibatch loss at step %d: %f" % (step, l))
      print("Minibatch accuracy: %.1f%%" % accuracy(predictions, batch_labels))
      print("Validation accuracy: %.1f%%" % accuracy(valid_prediction.eval(), valid_labels))
        
  print("Test accuracy: %.1f%%" % accuracy(test_prediction.eval(), test_labels))


    



In [ ]:

    
def xavier_init(n_inputs, n_outputs, uniform=True):
  """Set the parameter initialization using the method described.
  This method is designed to keep the scale of the gradients roughly the same
  in all layers.
  Xavier Glorot and Yoshua Bengio (2010):
           Understanding the difficulty of training deep feedforward neural
           networks. International conference on artificial intelligence and
           statistics.
  Args:
    n_inputs: The number of input nodes into each output.
    n_outputs: The number of output nodes for each input.
    uniform: If true use a uniform distribution, otherwise use a normal.
  Returns:
    An initializer.
  """
  if uniform:
    # 6 was used in the paper.
    init_range = math.sqrt(6.0 / (n_inputs + n_outputs))
    return tf.random_uniform_initializer(-init_range, init_range)
  else:
    # 3 gives us approximately the same limits as above since this repicks
    # values greater than 2 standard deviations from the mean.
    stddev = math.sqrt(3.0 / (n_inputs + n_outputs))
    return tf.truncated_normal_initializer(stddev=stddev)


    

