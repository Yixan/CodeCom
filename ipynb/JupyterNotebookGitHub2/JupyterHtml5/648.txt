
In [2]:

    
import numpy as np
import tensorflow as tf
from sklearn.utils import shuffle
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

rng = np.random.RandomState(1234)
random_state = 42


    



In [3]:

    
mnist = tf.keras.datasets.mnist

(x_train, t_train), (x_valid, t_valid) = mnist.load_data()

x_train = (x_train.reshape(-1, 28, 28, 1) / 255).astype(np.float32)
x_valid = (x_valid.reshape(-1, 28, 28, 1) / 255).astype(np.float32)

t_train = np.eye(10)[t_train].astype(np.float32)
t_valid = np.eye(10)[t_valid].astype(np.float32)


    



In [ ]:

    
tf.reset_default_graph()

# 入力 (4次元)
x = tf.placeholder(tf.float32)

# サンプル画像
sample_image = np.array([[1, 1, 1, 0, 0],
                         [0, 1, 1, 1, 0],
                         [0, 0, 1, 1, 1],
                         [0, 0, 1, 1, 0],
                         [0, 1, 1, 0, 0]]
                       ).astype('float32').reshape(1, 5, 5, 1)  # バッチサイズ x 高さ x 幅 x チャンネル数

# フィルタ
W = np.array([[1, 0, 1],
              [0, 1, 0],
              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1) # 高さ x 幅 x 入力チャンネル数　x 出力チャンネル数


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')  # strides: [1, 高さ, 幅, 1]

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3, 3))


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(2, 2))


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5, 5))


    



In [ ]:

    
tf.reset_default_graph()

# 入力 (4次元)
x = tf.placeholder(tf.float32)

# サンプル画像
sample_image = np.array([[1, 1, 1, 0, 0, 1, 0],
                         [0, 1, 0, 1, 0, 1, 1],
                         [1, 0, 1, 1, 1, 0, 1],
                         [0, 0, 1, 1, 0, 1, 1],
                         [1, 1, 1, 1, 0, 0, 1],
                         [0, 1, 1, 1, 1, 1, 1],
                         [0, 1, 1, 0, 0, 1, 0]]
                       ).astype('float32').reshape(1, 7, 7, 1)

# フィルタ
W = np.array([[1, 0, 1],
              [0, 1, 0],
              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1)


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5, 5))


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3, 3))


    



In [ ]:

    
convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')

with tf.Session() as sess:
    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(7, 7))


    



In [ ]:

    
tf.reset_default_graph()

# 入力
x = tf.placeholder(tf.float32)

sample_image = np.array([[77, 80, 82, 78, 70],
                         [83, 78, 80, 83, 82],
                         [87, 82, 81, 80, 74],
                         [87, 87, 85, 77, 66],
                         [84, 79, 77, 78, 76]]
                        ).astype("float32").reshape(1, 5, 5, 1) # 高さ x 幅 x 入力チャンネル数　x 出力チャンネル数


    



In [ ]:

    
pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))


    



In [ ]:

    
pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(4, 4))


    



In [ ]:

    
pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))


    



In [ ]:

    
tf.reset_default_graph()

# 入力
x = tf.placeholder(tf.float32)

sample_image = np.array([[77, 80, 82, 78, 70, 76, 75],
                         [83, 78, 78, 73, 82, 82, 85],
                         [87, 82, 81, 80, 74, 88, 70],
                         [87, 87, 85, 77, 66, 83, 87],
                         [81, 83, 77, 79, 66, 83, 87],
                         [87, 87, 83, 70, 66, 83, 87],
                         [84, 79, 77, 78, 76, 75, 80]]
                        ).astype("float32").reshape(1, 7, 7, 1)


    



In [ ]:

    
pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3, 3))


    



In [ ]:

    
pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(6, 6))


    



In [ ]:

    
pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')

with tf.Session() as sess:
    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3, 3))


    



In [ ]:

    
np.prod([2,3,2])


    



In [ ]:

    
class Conv:
    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):
        # Heの初期値
        fan_in = np.prod(filter_shape[:3]) # filter_shape: (縦の次元数)x(横の次元数)x(入力チャンネル数)x(出力チャンネル数)
        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]
        self.W = tf.Variable(rng.uniform(
                        low=-np.sqrt(6/fan_in),
                        high=np.sqrt(6/fan_in),
                        size=filter_shape
                    ).astype('float32'), name='W')
        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数
        self.function = function
        self.strides = strides
        self.padding = padding

    def __call__(self, x):
        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b
        return self.function(u)


    



In [ ]:

    
class Pooling:
    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):
        self.ksize = ksize
        self.strides = strides
        self.padding = padding
    
    def __call__(self, x):
        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)


    



In [ ]:

    
class Flatten:
    def __call__(self, x):
        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))


    



In [ ]:

    
class Dense:
    def __init__(self, in_dim, out_dim, function=lambda x: x):
        # He Initialization
        # in_dim: 入力の次元数、out_dim: 出力の次元数
        self.W = tf.Variable(rng.uniform(
                        low=-np.sqrt(6/in_dim),
                        high=np.sqrt(6/in_dim),
                        size=(in_dim, out_dim)
                    ).astype('float32'), name='W')
        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))
        self.function = function

    def __call__(self, x):
        return self.function(tf.matmul(x, self.W) + self.b)


    



In [ ]:

    
# tf.log(0)によるnanを防ぐ
def tf_log(x):
    return tf.log(tf.clip_by_value(x, 1e-10, x))


    



In [ ]:

    
tf.reset_default_graph()

x = tf.placeholder(tf.float32, [None, 28, 28, 1])
t = tf.placeholder(tf.float32, [None, 10])
                                                                          # (縦の次元数)x(横の次元数)x(チャネル数)
h = Conv((5, 5, 1, 20), tf.nn.relu)(x)           # 28x28x 1 -> 24x24x20
h = Pooling((1, 2, 2, 1))(h)                           # 24x24x20 -> 12x12x20
h = Conv((5, 5, 20, 50), tf.nn.relu)(h)        # 12x12x20 ->  8x 8x50
h = Pooling((1, 2, 2, 1))(h)                           #  8x 8x50 ->  4x 4x50
h = Flatten()(h)
y = Dense(4*4*50, 10, tf.nn.softmax)(h)

cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))
train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)


    



In [ ]:

    
n_epochs = 10
batch_size = 100
n_batches = x_train.shape[0]//batch_size

init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    for epoch in range(n_epochs):
        x_train, t_train = shuffle(x_train, t_train, random_state=random_state)
        for batch in range(n_batches):
            start = batch * batch_size
            end = start + batch_size
            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})
        y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})
        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(
            epoch,
            cost_valid,
            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))
        ))


    

