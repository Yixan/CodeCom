
In [ ]:

    
x = 10
y = x + 1
print(y)


    



In [ ]:

    
import tensorflow as tf

x = tf.constant(10, name='x')
y = tf.Variable(x + 1, name='y')

print(y)


    



In [ ]:

    
import tensorflow as tf

x = tf.constant(10, name='x')
y = tf.Variable(x + 1, name='y')

model = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(model)
    print(session.run(y))


    



In [ ]:

    
sess = tf.InteractiveSession()
a = tf.constant(5.0)
b = tf.constant(4.0)
c = a * b
print(c.eval()) # We can just use 'c.eval()' without passing 'sess'
sess.close()


    



In [ ]:

    
import tensorflow as tf

x = tf.placeholder("float", 3)
y = x * 4

with tf.Session() as session:
    result = session.run(y, feed_dict={x: [1, 2, 3]})
    print(result)


    



In [ ]:

    
import tensorflow as tf

x = tf.placeholder("float", None)
y = x * 4

with tf.Session() as session:
    result = session.run(y, feed_dict={x: [1, 2, 3, 4]})
    print(result)


    



In [ ]:

    
sess = tf.InteractiveSession()
x = tf.ones([2, 3], tf.int32)
print(x)
y = tf.constant([[1,1,1],[2,2,2]])
print(y.eval())
z = tf.add(x, y, name='sampleAdder')
print(z.eval())


    



In [ ]:

    
# practice with other valid arithmetic operators 
x = tf.ones([2, 3], tf.int32)
y = tf.constant([[1,1,1],[2,2,2]])
# z = ? # Please add your code here


    



In [ ]:

    
sess = tf.InteractiveSession()
x = -1 * tf.ones([2, 3], tf.int32)
print(x.eval())
z = tf.abs(x, name="absSample")
print(z.eval())


    



In [ ]:

    
sess = tf.InteractiveSession()
x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[1, 4], [5, 3]])
z = tf.pow(x, y)
print(z.eval())


    



In [ ]:

    
# practice with other valid basic math functions 
x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[1, 4], [5, 3]])
# z = ? # Please add your code here


    



In [ ]:

    
import numpy as np
sess = tf.InteractiveSession()
a = tf.constant(np.arange(1, 13, dtype=np.int32),
                shape=[2, 2, 3])                
b = tf.constant(np.arange(13, 25, dtype=np.int32),
                shape=[2, 3, 2])                
c = tf.matmul(a, b) 
print(c.eval())


    



In [ ]:

    
# practice with other valid matrix math functions 
a = tf.constant(np.arange(1, 13, dtype=np.int32),
                shape=[2, 2, 3])                
b = tf.constant(np.arange(13, 25, dtype=np.int32),
                shape=[2, 3, 2])  
# z = ? # Please add your code here


    



In [ ]:

    
# input data for mnist
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)


    



In [ ]:

    
# These are just helper functions, don't bother yourself to learn now
def displayDigit(image, label, num):
    label = label.argmax(axis=0)
    image = image.reshape([28,28])
    plt.title('Example: %d  Label: %d' % (num, label))
    plt.imshow(image, cmap=plt.get_cmap('gray_r'))
    plt.show()

def displayMultFlat(dataset, start, stop):
    images = dataset[start].reshape([1,784])
    for i in range(start+1,stop):
        images = np.concatenate((images, dataset[i].reshape([1,784])))
    plt.imshow(images, cmap=plt.get_cmap('gray_r'))
    plt.show()


    



In [ ]:

    
import numpy as np
import matplotlib.pyplot as plt

random = np.random.randint(0, 55000)
image = mnist.train.images[random,:]
label = mnist.train.labels[random,:]
displayDigit(image, label, random)


    



In [ ]:

    
displayMultFlat(mnist.train.images[0:300,:], 0, 300)


    



In [ ]:

    
x = tf.placeholder(tf.float32, [None, 784]) # input
y = tf.placeholder(tf.float32, [None, 10]) # Ground Truth

wFC1 = tf.Variable(tf.random_normal([784, 1024]))
bFC1 = tf.Variable(tf.random_normal([1024]))

fc1 = tf.add(tf.matmul(x, wFC1), bFC1)
fc1 = tf.nn.relu(fc1)

# output
wOut = tf.Variable(tf.random_normal([1024, 10]))
bOut = tf.Variable(tf.random_normal([10]))

output = tf.add(tf.matmul(fc1, wOut), bOut) 

# train the network
pred = output

# Define loss and optimizer
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)

# Evaluate model
correctPred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))

# Initializing the variables
sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)
numTrain = 5500
numTest = 1000

for i in range(5):
    sess.run(optimizer, feed_dict={x: mnist.train.images[:numTrain,:], y: mnist.train.labels[:numTrain,:]})
    print('Training Step:' + str(i) + '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})) + '  Loss = ' + str(sess.run(cost, {x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})))


    



In [ ]:

    
# train again with mini batch
import tensorflow as tf
tf.reset_default_graph()
x = tf.placeholder(tf.float32, [None, 784])
y = tf.placeholder(tf.float32, [None, 10])
wFC1 = tf.Variable(tf.random_normal([784, 1024]))
bFC1 = tf.Variable(tf.random_normal([1024]))

fc1 = tf.add(tf.matmul(x, wFC1), bFC1)
fc1 = tf.nn.relu(fc1)

# output
wOut = tf.Variable(tf.random_normal([1024, 10]))
bOut = tf.Variable(tf.random_normal([10]))

output = tf.add(tf.matmul(fc1, wOut), bOut) 

pred = output
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)
correctPred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))

sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

batchSize = 10
numEpoch = 5
numTrain = 5500
numTest = 1000
for i in range(numEpoch): # epoch
    for j in range(numTrain//batchSize): #mini batch
        batchX, batchY = mnist.train.next_batch(batchSize)
        sess.run(optimizer, feed_dict={x: batchX, y: batchY})
    print('Training Step:' + str(i) + '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})) + '  Loss = ' + str(sess.run(cost, {x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})))


    



In [ ]:

    
import tensorflow as tf
tf.reset_default_graph()
# x = ?
y = tf.placeholder(tf.float32, [None, 10])

wC1 = tf.Variable(tf.random_normal([5, 5, 1, 32]))
bC1 = tf.Variable(tf.random_normal([32]))

stride = 1
xReshap = tf.reshape(x, shape=[-1, 28, 28, 1])
conv1 = tf.nn.conv2d(xReshap, wC1, strides=[1, stride, stride, 1], padding='SAME')
conv1 = tf.nn.bias_add(conv1, bC1)
conv1 = tf.nn.relu(conv1)

kernelSize = 2 # max pooling
conv1 = tf.nn.max_pool(conv1, ksize=[1, kernelSize, kernelSize, 1], strides=[1, kernelSize, kernelSize, 1],
                          padding='SAME')


# Please put the right number in the right place and replace questions marks
# after that you can uncomment those lines
# wC2 = tf.Variable(tf.random_normal([?, ?, 32, 64]))
# bC2 = tf.Variable(tf.random_normal([?]))

stride = 1
# conv2 = tf.nn.conv2d(?, wC2, strides=[1, stride, stride, 1], padding='SAME')
conv2 = tf.nn.bias_add(conv2, bC2)
conv2 = tf.nn.relu(conv2)

kernelSize = 2
conv2 = tf.nn.max_pool(conv2, ksize=[1, kernelSize, kernelSize, 1], strides=[1, kernelSize, kernelSize, 1],
                          padding='SAME')

fc1 = tf.reshape(conv2, [-1, 64*7*7])
print(fc1.get_shape())

# wFC1 = ?
bFC1 = tf.Variable(tf.random_normal([1024]))

fc1 = tf.add(tf.matmul(fc1, wFC1), bFC1)
fc1 = tf.nn.relu(fc1)

# output
wOut = tf.Variable(tf.random_normal([1024, 10]))
bOut = tf.Variable(tf.random_normal([10]))

output = tf.add(tf.matmul(fc1, wOut), bOut) 

pred = output
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)
# correctPred = tf.equal(tf.argmax(?, 1), tf.argmax(?, 1))
accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))

sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

batchSize = 10
numEpoch = 5
numTrain = 5500
numTest = 1000
for i in range(numEpoch): # epoch
    for j in range(numTrain//batchSize): #mini batch
        batchX, batchY = mnist.train.next_batch(batchSize)
        sess.run(optimizer, feed_dict={x: batchX, y: batchY})
    print('Training Step:' + str(i) + '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})) + '  Loss = ' + str(sess.run(cost, {x: mnist.test.images[:numTest,:], y: mnist.test.labels[:numTest,:]})))


    



In [ ]:

    
import tensorflow as tf

x = tf.constant(10, name='x')
y = tf.Variable(x + 1, name='y')

with tf.Session() as session:
    merged = tf.summary.merge_all()
    writer = tf.summary.FileWriter("./tmp/basic", session.graph)
    model =  tf.global_variables_initializer()
    session.run(model)
    print(session.run(y))


    



In [ ]:

    
# I wish you all the best 
# Mojtaba Valipour @ Shiraz University


    

