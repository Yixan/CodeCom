from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.advanced_activations import PReLU
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD, Adadelta, Adagrad
from keras.layers.wrappers import TimeDistributed
from keras.layers.normalization import BatchNormalization
from keras.layers import LSTM, SimpleRNN, GRU
from keras.layers import Merge
from phcx import *
import numpy as np
import os
from keras.utils import np_utils, generic_utils
def lenet5(CNN_INPUT_length, CNN_INPUT_width):
    model = Sequential()
    model.add(Convolution2D(4, 5, 5, border_mode='valid',put_shape=(1, CNN_INPUT_length, CNN_INPUT_width)))
    model.add(Convolution2D(8, 3, 3, subsample=(2, 2),border_mode='valid'))
    model.add(Activation('relu'))
    model.add(Convolution2D(16, 3, 3, subsample=(2, 2), border_mode='valid'))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
    return model
def get_data(filePath,mode):
    if mode == 'train':
        pulsar_file_base = filePath + 'pulsars_train\\'
        rfi_file_base = filePath + 'RFI_train\\'
    else:
        pulsar_file_base = filePath + 'pulsars_test\\'
        rfi_file_base = filePath + 'RFI_test\\'
    pulsar_files = os.listdir(pulsar_file_base)
    rfi_files = os.listdir(rfi_file_base)
    cnn_input = np.empty((len(pulsar_files)+len(rfi_files), 1, 16, 64), dtype='float32')
    lstm_input = np.empty((len(pulsar_files)+len(rfi_files), 18, 64), dtype='float32')
    train_label = [1]*len(pulsar_files)
    train_label.extend([0]*len(rfi_files))
    trainlabel = np_utils.to_categorical(train_label, 2)
    train_num = 0
    for filename in pulsar_files:
        cand = Candidate(pulsar_file_base + filename)
        cnn_input[train_num,:,:,:] = np.resize(cand.subbands,(16,64))
        lstm_input[train_num,:,:] = np.resize(cand.subints,(18,64))
        train_num +=1
    for filename in rfi_files:
        cand = Candidate(rfi_file_base + filename)
        cnn_input[train_num,:,:,:] = np.resize(cand.subbands,(16,64))
        lstm_input[train_num,:,:] = np.resize(cand.subints,(18,64))
        train_num +=1
    return cnn_input,lstm_input,trainlabel
def main():
    model_cnn = lenet5(16,64)
    model_lstm = Sequential()
    model_lstm.add(Dense(64))
    model_lstm.add(BatchNormalization())
    merged = Merge([model_cnn,model_lstm],mode='concat')
    model = Sequential()
    model.add(merged)
    model.add(Dense(2,activation='softmax'))
    optimizer_ins = SGD(lr=0.01, momentum=0.9, decay=0.00, nesterov=False)
    model.compile(loss='binary_crossentropy',optimizer=optimizer_ins,trics = ['accuracy','precision'])
    model_lstm.summary()
    print('LSTM training...')
    filePath = 'H:\\研究生\\1-SKA\\Data\\MedlatTrainingData\\'
    train_data_cnn,train_data_lstm,train_label = get_data(filePath,'train')
    model.fit([train_data_cnn,train_data_lstm], train_label, batch_size=32, nb_epoch=1)
    test_data_cnn,test_data_lstm,test_label = get_data(filePath,'test')
    model.evaluate([test_data_cnn,test_data_lstm],test_label,batch_size = 16)
if __name__ == '__main__':
    main()